{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '</kaggle/input/real-estate-price-prediction-moscow>/train.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-bc5d65b31627>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     39\u001b[0m '''    \n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m \u001b[0mtrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'</kaggle/input/real-estate-price-prediction-moscow>/train.csv'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#-здесь нескончаемая ошибка без указания полного пути к папке (скачивала несколько раз, пропадает после операции)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'</kaggle/input/real-estate-price-prediction-moscow>/test.csv'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#-аналогична предыдущей\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"База загружена\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    684\u001b[0m     )\n\u001b[1;32m    685\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 686\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    688\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    450\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    451\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 452\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    453\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    454\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    944\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    945\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 946\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    947\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    948\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1176\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1177\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1178\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1179\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1180\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   2006\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2007\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2008\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2009\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2010\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '</kaggle/input/real-estate-price-prediction-moscow>/train.csv'"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Sun Jan 08 17:25:00 2021\n",
    "\n",
    "@author: ginodaurini\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from scipy.stats import norm\n",
    "from scipy import stats\n",
    "\n",
    "# %matplotlib inline\n",
    "# %config InlineBackend.figure_format = 'svg'\n",
    "\n",
    "'''\n",
    "def optimizing_df(df):\n",
    "    for col in df.columns:\n",
    "        if df[col].dtypes.kind == 'i' or df[col].dtypes.kind == 'u':\n",
    "            if df[col].min() >= 0:\n",
    "                df[col] = pd.to_numeric(df[col], downcast='unsigned')\n",
    "            else:\n",
    "                df[col] = pd.to_numeric(df[col], downcast='integer')\n",
    "\n",
    "        elif df[col].dtypes.kind == 'f' or df[col].dtypes.kind == 'c':\n",
    "            df[col] = pd.to_numeric(df[col], downcast='float')\n",
    "\n",
    "        elif df[col].dtypes.kind == 'O':\n",
    "            num_unique_values = len(df[col].unique())\n",
    "            num_total_values = len(df[col])\n",
    "            if num_unique_values / num_total_values < 0.5:\n",
    "                df[col] = df[col].astype('category')\n",
    "\n",
    "    return df\n",
    "'''    \n",
    "\n",
    "train = pd.read_csv('</kaggle/input/real-estate-price-prediction-moscow>/train.csv') #-здесь нескончаемая ошибка без указания полного пути к папке (скачивала несколько раз, пропадает после операции)\n",
    "test = pd.read_csv('</kaggle/input/real-estate-price-prediction-moscow>/test.csv') #-аналогична предыдущей\n",
    "print(\"База загружена\")\n",
    "\n",
    "print(f\"Train:\\t{train.shape[0]}\\t sales and {train.shape[1]} features\")\n",
    "print(f'Test:\\t{test.shape[0]}\\t sales and {test.shape[1]} features')\n",
    "\n",
    "test.head()\n",
    "train.head()\n",
    "\n",
    "train.info(memory_usage='deep')\n",
    "test.info(memory_usage='deep')\n",
    "\n",
    "train['Rooms'] = train['Rooms'].astype('int64')\n",
    "test['Rooms'] = test['Rooms'].astype('int64')\n",
    "\n",
    "train['HouseFloor'] = train['HouseFloor'].astype('int64')\n",
    "test['HouseFloor'] = test['HouseFloor'].astype('int64')\n",
    "\n",
    "train = optimizing_df(train)\n",
    "test = optimizing_df(test)\n",
    "\n",
    "train.info(memory_usage='deep')\n",
    "\n",
    "test.info(memory_usage='deep')\n",
    "\n",
    "all_data = pd.concat((train, test), sort=False).reset_index(drop=True)\n",
    "all_data.drop(['Price'], axis=1, inplace=True)\n",
    "print(f'all_data size is : {all_data.shape}')\n",
    "\n",
    "all_data.describe().transpose()\n",
    "\n",
    "all_data.loc[all_data['Rooms'] > 6]\n",
    "\n",
    "all_data.loc[all_data['Rooms'] == 0]\n",
    "\n",
    "'''\n",
    "def df_fix_room(df):\n",
    "    info_by_district_id = df.groupby(['DistrictId', 'HouseYear'], as_index=False).agg(\n",
    "        {'Rooms': 'sum', 'Square': 'sum'}).rename(\n",
    "        columns={'Rooms': 'sum_roos_dr', 'Square': 'sum_square_dr'})\n",
    "\n",
    "    info_by_district_id['mean_square_per_room_in_dr'] = info_by_district_id['sum_square_dr'] \\\n",
    "        / info_by_district_id['sum_roos_dr']\n",
    "    info_by_district_id.drop(\n",
    "        ['sum_square_dr', 'sum_roos_dr'], axis=1, inplace=True)\n",
    "\n",
    "    df = pd.merge(df, info_by_district_id, on=[\n",
    "                  'DistrictId', 'HouseYear'], how='left')\n",
    "\n",
    "    df['mean_square_per_room_in_dr'] = df['mean_square_per_room_in_dr'].fillna(\n",
    "        df['mean_square_per_room_in_dr'].mean())\n",
    "\n",
    "    df.loc[df['Rooms'] > 6, 'Rooms'] \\\n",
    "        = (df.loc[df['Rooms'] > 6, 'Square']\n",
    "           // df.loc[df['Rooms'] > 6, 'mean_square_per_room_in_dr']).astype('int')\n",
    "\n",
    "    df.loc[df['Rooms'] == 0, 'Rooms'] \\\n",
    "        = (df.loc[df['Rooms'] == 0, 'Square']\n",
    "           // df.loc[df['Rooms'] == 0, 'mean_square_per_room_in_dr']).astype('int')\n",
    "\n",
    "    df.loc[df['Rooms'] == 0, 'Rooms'] = 1\n",
    "    return df\n",
    "'''\n",
    "\n",
    "\n",
    "all_data.loc[all_data['Square'] > 200].nlargest(20, 'Square')\n",
    "\n",
    "sns.distplot(all_data['Square'], fit=norm)\n",
    "\n",
    "mu, sigma = norm.fit(all_data['Square'])\n",
    "\n",
    "print(f'mu = {mu:.2f} and sigma = {sigma:.2f}')\n",
    "\n",
    "plt.legend(\n",
    "    [f'Normal dist. ($\\mu=$ {mu:.2f} and $\\sigma=$ {sigma:.2f} )'])\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Square distribution')\n",
    "\n",
    "# QQ-plot\n",
    "fig = plt.figure()\n",
    "res = stats.probplot(all_data['Square'], plot=plt)\n",
    "plt.show()\n",
    "\n",
    "'''\n",
    "def df_fix_square_manual(df):\n",
    "    df.loc[df['Square'] > 400, 'Square'] = df.loc[df['Square'] > 400, 'Square'] / 10\n",
    "    return df\n",
    "\n",
    "def df_fix_square(df):\n",
    "    info_by_district_id = df.groupby(['DistrictId', 'Rooms', 'HouseYear'], as_index=False).agg(\n",
    "        {'Square': 'mean'}).rename(\n",
    "        columns={'Square': 'mean_square_rooms_dr'})\n",
    "\n",
    "    df = pd.merge(df, info_by_district_id, on=[\n",
    "        'DistrictId', 'Rooms', 'HouseYear'], how='left')\n",
    "\n",
    "    df.loc[abs(df['Square'] - df['mean_square_rooms_dr']) > 2 * sigma, 'Square'] \\\n",
    "        = df.loc[abs(df['Square'] - df['mean_square_rooms_dr']) > 2 * sigma, 'Rooms'] \\\n",
    "        * df.loc[abs(df['Square'] - df['mean_square_rooms_dr']) > 2 * sigma, 'mean_square_per_room_in_dr']\n",
    "    return df\n",
    "    \n",
    "def prepare_lifesquare(df):\n",
    "    df.loc[df['Square'] < df['LifeSquare'],\n",
    "           'LifeSquare'] = df.loc[df['Square'] < df['LifeSquare'], 'Square']\n",
    "    return df\n",
    "\n",
    "\n",
    "def fillna_life_square(df):\n",
    "    df['LifeSquare'] = df['LifeSquare'].fillna(df['LifeSquare'].mean())\n",
    "    return df\n",
    "'''\n",
    "\n",
    "all_data.loc[all_data['HouseYear'] > 2020]\n",
    "\n",
    "'''\n",
    "def df_fix_house_year_manual(df):\n",
    "    df.loc[df['HouseYear'] == 20052011, 'HouseYear'] = int((2005 + 2011) / 2)\n",
    "    df.loc[df['HouseYear'] == 4968, 'HouseYear'] = 1968\n",
    "    return df\n",
    "'''\n",
    "\n",
    "#DATA PROCESSING\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "\n",
    "# Целевая переменная\n",
    "\n",
    "sns.distplot(train['Price'], fit=norm)\n",
    "mu, sigma = norm.fit(train['Price'])\n",
    "print(f'mu = {mu:.2f} and sigma = {sigma:.2f}')\n",
    "plt.legend(\n",
    "    [f'Normal dist. ($\\mu=$ {mu:.2f} and $\\sigma=$ {sigma:.2f} )'], loc='best')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Price distribution')\n",
    "# QQ-plot\n",
    "fig = plt.figure()\n",
    "res = stats.probplot(train['Price'], plot=plt)\n",
    "plt.show()\n",
    "\n",
    "price_log = np.log1p(train['Price'])\n",
    "sns.distplot(price_log, fit=norm)\n",
    "mu, sigma = norm.fit(train['Price'])\n",
    "print(f'mu = {mu:.2f} and sigma = {sigma:.2f}')\n",
    "plt.legend(\n",
    "    [f'Normal dist. ($\\mu=$ {mu:.2f} and $\\sigma=$ {sigma:.2f} )'], loc='best')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Price distribution')\n",
    "# QQ-plot\n",
    "fig = plt.figure()\n",
    "res = stats.probplot(price_log, plot=plt)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(18, 6))\n",
    "sns.barplot(train['HouseYear'], train['Price'])\n",
    "plt.xticks(rotation=90)\n",
    "plt.title('Distribution of variable House Year')\n",
    "\n",
    "plt.figure(figsize=(18, 6))\n",
    "sns.barplot(train['DistrictId'], train['Price'])\n",
    "plt.xticks(rotation=90)\n",
    "plt.title('Distribution of variable District Id')\n",
    "\n",
    "#инженерные особенности\n",
    "all_data = pd.concat((train, test), sort=False).reset_index(drop=True)\n",
    "all_data.drop(['Price'], axis=1, inplace=True)\n",
    "print(f'all_data size is : {all_data.shape}')\n",
    "\n",
    "all_data_na = (all_data.isnull().sum() / len(all_data)) * 100\n",
    "all_data_na = all_data_na.drop(\n",
    "    all_data_na[all_data_na == 0].index).sort_values(ascending=False)\n",
    "missing_data = pd.DataFrame({'Missing Ratio': all_data_na})\n",
    "missing_data\n",
    "\n",
    "'''\n",
    "def df_del_missing(df):\n",
    "    df_na = (df.isnull().sum() / len(df)) * 100\n",
    "\n",
    "    df_na = df_na.drop(\n",
    "        df_na[df_na == 0].index).sort_values(ascending=False)\n",
    "    df_na = list(df_na.index)\n",
    "    df.drop(df_na, axis=1, inplace=True)\n",
    "    return df\n",
    "'''\n",
    "#корреляция\n",
    "corrmat = train.loc[:, train.columns != 'Id'].corr()\n",
    "plt.subplots(figsize=(12, 9))\n",
    "sns.heatmap(corrmat, vmax=0.9, square=True)\n",
    "\n",
    "corrmat = train.loc[:, train.columns != 'Id'].corrwith(\n",
    "    train['Price']).abs().sort_values(ascending=False)[1:]\n",
    "plt.bar(corrmat.index, corrmat.values)\n",
    "plt.title('Correlation to Price')\n",
    "plt.xticks(rotation='vertical')\n",
    "plt.show()\n",
    "train.head()\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "train_cluster = train.copy()\n",
    "train_cluster = df_fix_house_year_manual(train_cluster)\n",
    "train_cluster_scaled = pd.DataFrame(scaler.fit_transform(\n",
    "    train_cluster.loc[:, ['HouseYear', 'Price']]), columns=['HouseYear', 'Price'])\n",
    "\n",
    "inertias = []\n",
    "for i in range(2, 10):\n",
    "    temp_model = KMeans(n_clusters=i, random_state=100)\n",
    "    temp_model.fit(train_cluster_scaled)\n",
    "    temp_inertia = temp_model.inertia_\n",
    "    inertias.append(temp_inertia)\n",
    "\n",
    "plt.plot(range(2, 10), inertias)\n",
    "plt.title('Inertia')\n",
    "plt.show()\n",
    "\n",
    "plt.scatter(train_cluster_scaled['HouseYear'], train_cluster_scaled['Price'])\n",
    "plt.xlabel('HouseYear')\n",
    "plt.ylabel('Price')\n",
    "plt.show()\n",
    "\n",
    "kmeans_model = KMeans(n_clusters=5, random_state=100)\n",
    "train_labels = kmeans_model.fit_predict(train_cluster_scaled)\n",
    "plt.scatter(train_cluster_scaled['HouseYear'],\n",
    "            train_cluster_scaled['Price'], c=train_labels)\n",
    "plt.xlabel('HouseYear')\n",
    "plt.ylabel('Price')\n",
    "plt.title('Train data')\n",
    "\n",
    "agglomerative_clustering_model = AgglomerativeClustering(n_clusters=5)\n",
    "train_cluster['cluster_year'] = agglomerative_clustering_model.fit_predict(train_cluster_scaled)\n",
    "plt.scatter(train_cluster['HouseYear'],\n",
    "            train_cluster['Price'], c=train_cluster['cluster_year'])\n",
    "plt.xlabel('HouseYear')\n",
    "plt.ylabel('Price')\n",
    "plt.title('Train')\n",
    "\n",
    "'''\n",
    "def add_cluster_year(df):\n",
    "    df_scaled = pd.DataFrame(scaler.fit_transform(\n",
    "        df.loc[:, ['HouseYear']]), columns=['HouseYear'])\n",
    "    df['cluster_year'] = agglomerative_clustering_model.fit_predict(df_scaled)\n",
    "    return df\n",
    "\n",
    "def add_mean_price(df, df_train=train):\n",
    "    price = df_train['Price'].mean()\n",
    "    price_mean_by_rooms = df_train.groupby(['Rooms'], as_index=False).agg({'Price': 'mean'}).\\\n",
    "        rename(columns={'Price': 'mean_price_by_rooms'})\n",
    "\n",
    "    price_mean_by_distr_rooms = df_train.groupby(['DistrictId', 'Rooms'], as_index=False).agg({'Price': 'mean'}).\\\n",
    "        rename(columns={'Price': 'mean_price_dr'})\n",
    "\n",
    "    df = pd.merge(df, price_mean_by_distr_rooms, on=[\n",
    "                  'DistrictId', 'Rooms'], how='left')\n",
    "    df = pd.merge(df, price_mean_by_rooms, on='Rooms', how='left')\n",
    "    df['mean_price_dr'] = df['mean_price_dr'].fillna(df['mean_price_by_rooms'])\n",
    "    df['mean_price_dr'] = df['mean_price_dr'].fillna(price)\n",
    "    df['mean_price_by_rooms'] = df['mean_price_by_rooms'].fillna(price)\n",
    "    return df\n",
    "    \n",
    "def add_distr_info(df):\n",
    "    distr_info = df['DistrictId'].value_counts().reset_index().\\\n",
    "        rename(columns={\"index\": \"DistrictId\", \"DistrictId\": 'large_district'})\n",
    "    df = pd.merge(df, distr_info, on='DistrictId', how='left')\n",
    "    df['large_district'] = df['large_district'].fillna(1)\n",
    "    return df\n",
    "'''\n",
    "\n",
    "#ФУНКЦИЯ\n",
    "'''\n",
    "def data_prepare(df, df_train=train):\n",
    "    df = df_fix_square_manual(df)\n",
    "    df = df_fix_house_year_manual(df)\n",
    "    df = df_fix_room(df)\n",
    "    df = df_fix_square(df)\n",
    "    df = prepare_lifesquare(df)\n",
    "    df = fillna_life_square(df)\n",
    "    df = df_del_missing(df)\n",
    "    df = add_cluster_year(df)\n",
    "    df = add_mean_price(df, df_train)\n",
    "    df = add_distr_info(df)\n",
    "    df = pd.get_dummies(df)\n",
    "    df.drop('mean_square_per_room_in_dr', axis=1, inplace=True)\n",
    "    df.drop('mean_square_rooms_dr', axis=1, inplace=True)\n",
    "    optimizing_df(df)\n",
    "    return df\n",
    "\n",
    "\n",
    "def model_test(model, name, test, valid):\n",
    "    model_pred = model.predict(test)\n",
    "    r2 = r2_score(valid, model_pred)\n",
    "    mse = mean_squared_error(valid, model_pred)\n",
    "    plt.scatter(valid, (model_pred - valid))\n",
    "    plt.xlabel(\"Predicted values\")\n",
    "    plt.ylabel(\"Real values\")\n",
    "    plt.title(name)\n",
    "    plt.legend([f'R2= {r2:.4f} and mse= {mse:.0e}'])\n",
    "    plt.axhline(0, color='red')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def model_top_deviation(model, test, valid):\n",
    "    model_pred = model.predict(test)\n",
    "    model_test = test.copy()\n",
    "    model_test['Price'] = model_pred\n",
    "    model_test['Price_test'] = valid\n",
    "    model_test['SD'] = abs(model_test['Price']\n",
    "                           - model_test['Price_test'])\n",
    "    return model_test.nlargest(10, 'SD')\n",
    "'''\n",
    "\n",
    "#Загрузка пакетов\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.linear_model import LassoCV\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "print(train.columns)\n",
    "\n",
    "features = list(train.loc[:, train.columns != 'Id'].corrwith(\n",
    "    train['Price']).abs().sort_values(ascending=False)[1:].index)\n",
    "target = 'Price'\n",
    "train[features].head()\n",
    "\n",
    "models_dict = {}\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    train[features], train[target], test_size=0.3, random_state=42)\n",
    "X_train = data_prepare(X_train, train)\n",
    "X_test = data_prepare(X_test, train)\n",
    "X_train.info()\n",
    "X_test.info()\n",
    "X_train.head()\n",
    "y_train.head()\n",
    "\n",
    "#Линейная регрессия\n",
    "line_regression_model = LinearRegression()\n",
    "line_regression_model.fit(X_train, y_train)\n",
    "models_dict['Linear Regression'] = line_regression_model\n",
    "\n",
    "#тест регрессии\n",
    "model_test(line_regression_model, 'Linear Regression', X_test, y_test)\n",
    "model_top_deviation(line_regression_model, X_test, y_test)\n",
    "\n",
    "#RF регрессия\n",
    "random_forest_regressor_model = RandomForestRegressor()\n",
    "random_forest_regressor_model.fit(X_train, y_train)\n",
    "models_dict['Random Forest Regressor'] = random_forest_regressor_model\n",
    "\n",
    "#тест RF\n",
    "model_test(random_forest_regressor_model,\n",
    "           'Random Forest Regressor', X_test, y_test)\n",
    "model_top_deviation(random_forest_regressor_model, X_test, y_test)\n",
    "\n",
    "#GradientBoosting регрессия\n",
    "gradient_boosting_regressor_model = GradientBoostingRegressor()\n",
    "gradient_boosting_regressor_model.fit(X_train, y_train)\n",
    "models_dict['Gradient Boosting Regressor'] = gradient_boosting_regressor_model\n",
    "\n",
    "#тест GradientBoosting\n",
    "model_test(gradient_boosting_regressor_model,\n",
    "           'Gradient Boosting Regressor', X_test, y_test)\n",
    "model_top_deviation(gradient_boosting_regressor_model, X_test, y_test)\n",
    "\n",
    "#Lasso CV\n",
    "lasso_cv_model = LassoCV()\n",
    "lasso_cv_model.fit(X_train, y_train)\n",
    "models_dict['LassoCV'] = lasso_cv_model\n",
    "\n",
    "#тест lasso CV\n",
    "model_test(lasso_cv_model, 'LassoCV', X_test, y_test)\n",
    "model_top_deviation(lasso_cv_model, X_test, y_test)\n",
    "all_data.loc[all_data['KitchenSquare'] < 3]\n",
    "\n",
    "#LGBMRegressor\n",
    "lgbm_regressor_model = LGBMRegressor()\n",
    "lgbm_regressor_model.fit(X_train, y_train)\n",
    "\n",
    "#тест ДПИЬКкупкуыыщк\n",
    "model_test(lgbm_regressor_model, 'LGBMRegressor', X_test, y_test)\n",
    "model_top_deviation(lgbm_regressor_model, X_test, y_test)\n",
    "\n",
    "#тюнинг\n",
    "lgbm_regressor_model.get_params\n",
    "np.arange(0.01, 0.05, 0.01)\n",
    "parameters = [{\n",
    "    'max_bin': np.arange(90, 120, 10),\n",
    "    'n_estimators': np.arange(4000, 7000, 1000),\n",
    "    'learning_rate': np.arange(0.01, 0.05, 0.01)\n",
    "}]\n",
    "clf = GridSearchCV(\n",
    "    estimator=LGBMRegressor(random_state=42),\n",
    "    param_grid=parameters,\n",
    "    scoring='neg_mean_squared_error',\n",
    "    cv=4,\n",
    "    n_jobs=-1,\n",
    ")\n",
    "clf.fit(X_train, y_train)\n",
    "cv_results = pd.DataFrame(clf.cv_results_)\n",
    "param_columns = [\n",
    "    column\n",
    "    for column in cv_results.columns\n",
    "    if column.startswith('param_')\n",
    "]\n",
    "score_columns = ['mean_test_score']\n",
    "cv_results = (cv_results[param_columns + score_columns]\n",
    "              .sort_values(by=score_columns, ascending=False))\n",
    "cv_results.head(10)\n",
    "clf.best_params_\n",
    "\n",
    "#тест тюнинга\n",
    "lgbm_regressor_model = LGBMRegressor(\n",
    "    max_bin=110,\n",
    "    num_leaves=4,\n",
    "    n_estimators=4000,\n",
    "    learning_rate=0.01\n",
    ")\n",
    "lgbm_regressor_model.fit(X_train, y_train)\n",
    "model_test(lgbm_regressor_model, 'LGBMRegressor', X_test, y_test)\n",
    "models_dict['LGBMRegressor'] = lgbm_regressor_model\n",
    "\n",
    "#XGBRegressor\n",
    "xgboost_model = XGBRegressor()\n",
    "xgboost_model.fit(X_train, y_train)\n",
    "models_dict['XGBRegressor'] = xgboost_model\n",
    "\n",
    "#тест ЧПИКупкуыыщк\n",
    "model_test(xgboost_model, 'XGBRegressor', X_test, y_test)\n",
    "model_top_deviation(xgboost_model, X_test, y_test)\n",
    "\n",
    "#РЕЗУЛЬТАТ\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "'''\n",
    "def models_r2(models, test, valid):\n",
    "    scores = pd.DataFrame(columns=['name', 'r2', 'mse'])\n",
    "    for name, model in models.items():\n",
    "        test_pred = model.predict(test)\n",
    "        r2 = r2_score(valid, test_pred)\n",
    "        mse = mean_squared_error(valid, test_pred)\n",
    "        scores = scores.append(\n",
    "            {'name': name, 'r2': r2, 'mse': mse}, ignore_index=True)\n",
    "    scores.sort_values('r2', ascending=False, inplace=True)\n",
    "    return scores\n",
    "'''\n",
    "\n",
    "models_score_test = models_r2(models_dict, X_test, y_test)\n",
    "models_score_train = models_r2(models_dict, X_train, y_train)\n",
    "models_score_test[['name', 'r2']]\n",
    "r2_max_test = models_score_test['r2'].max()\n",
    "r2_max_train = models_score_train['r2'].max()\n",
    "plt.barh(models_score_test['name'], models_score_test['r2'],\n",
    "         alpha=0.5, color='red', label=f'Test  Data: R2 max: {r2_max_test:.4f}')\n",
    "plt.barh(models_score_train['name'], models_score_train['r2'],\n",
    "         alpha=0.5, color='grey', label=f'Train Data: R2 max: {r2_max_train:.4f}')\n",
    "plt.title('R2')\n",
    "plt.legend()\n",
    "plt.axvline(0.6, color='red')\n",
    "plt.axvline(r2_max_test, color='green')\n",
    "plt.show()\n",
    "\n",
    "mse_min_test = models_score_test['mse'].min()\n",
    "mse_min_train = models_score_train['mse'].min()\n",
    "plt.barh(models_score_test['name'], models_score_test['mse'],\n",
    "         alpha=0.5, color='red', label=f'Test  Data MSE min: {mse_min_test:.0e}')\n",
    "plt.barh(models_score_train['name'], models_score_train['mse'],\n",
    "         alpha=0.5, color='grey', label=f'Train Data MSE min: {mse_min_train:.0e}')\n",
    "plt.title('Mean squared error')\n",
    "plt.legend(loc=2)\n",
    "plt.axvline(mse_min_test, color='green')\n",
    "plt.show()\n",
    "\n",
    "best_model = models_dict['LGBMRegressor']\n",
    "\n",
    "pd.DataFrame({'name': list(X_train.columns),\n",
    "              'importances': list(best_model.feature_importances_)})\n",
    "\n",
    "model_test(best_model, 'best_model', X_test, y_test)\n",
    "\n",
    "#OUTPUT\n",
    "test = data_prepare(test)\n",
    "test_features = list(X_train.columns)\n",
    "test[test_features].info()\n",
    "test['Price'] = best_model.predict(test[test_features])\n",
    "\n",
    "price_log = np.log1p(test['Price'])\n",
    "sns.distplot(price_log, fit=norm)\n",
    "mu, sigma = norm.fit(test['Price'])\n",
    "print(f'mu = {mu:.2f} and sigma = {sigma:.2f}')\n",
    "plt.legend(\n",
    "    [f'Normal dist. ($\\mu=$ {mu:.2f} and $\\sigma=$ {sigma:.2f} )'], loc='best')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Price distribution')\n",
    "# QQ-plot\n",
    "fig = plt.figure()\n",
    "res = stats.probplot(price_log, plot=plt)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '</kaggle/input/real-estate-price-prediction-moscow>/train.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-b61f37bdef6a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     31\u001b[0m '''    \n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m \u001b[0mtrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'</kaggle/input/real-estate-price-prediction-moscow>/train.csv'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#-здесь нескончаемая ошибка без указания полного пути к папке (скачивала несколько раз, пропадает после операции)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'</kaggle/input/real-estate-price-prediction-moscow>/test.csv'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#-аналогична предыдущей\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"База загружена\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    684\u001b[0m     )\n\u001b[1;32m    685\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 686\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    688\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    450\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    451\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 452\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    453\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    454\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    944\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    945\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 946\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    947\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    948\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1176\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1177\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1178\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1179\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1180\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   2006\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2007\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2008\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2009\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2010\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '</kaggle/input/real-estate-price-prediction-moscow>/train.csv'"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
